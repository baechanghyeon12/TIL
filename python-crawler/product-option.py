# import requests
# from bs4 import BeautifulSoup
# import pandas as pd
# import time
#
# # í¬ë¡¤ë§í•  ìƒí’ˆ ì½”ë“œ ë¦¬ìŠ¤íŠ¸
# g_no_list = [11548, 11549, 8754]  # ì˜ˆì‹œ ìƒí’ˆ ì½”ë“œ
# base_iframe_url = "https://www.lklab.com/product/product_info_order_job.asp?g_no="
#
# headers = {
#     "User-Agent": "Mozilla/5.0"
# }
#
# rows = []
#
# for g_no in g_no_list:
#     iframe_url = f"{base_iframe_url}{g_no}"
#     print(f"[INFO] ìƒí’ˆ {g_no} ì²˜ë¦¬ ì¤‘...")
#
#     try:
#         response = requests.get(iframe_url, headers=headers, timeout=15)
#         if response.status_code != 200:
#             print(f"  âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
#             continue
#
#         soup = BeautifulSoup(response.text, "html.parser")
#         item_codes = [td.get_text(strip=True) for td in soup.find_all("td", class_="pr22")]
#
#         if not item_codes:
#             print("  âš ï¸ í’ˆëª©ì½”ë“œ ì—†ìŒ")
#
#         # âœ… ì²« ë²ˆì§¸ í’ˆëª©ì€ g_no í¬í•¨, ì´í›„ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ í‘œì‹œ
#         for idx, item_code in enumerate(item_codes):
#             rows.append({
#                 "g_no": g_no if idx == 0 else "",
#                 "item_code": item_code
#             })
#
#         time.sleep(0.5)
#
#     except Exception as e:
#         print(f"  âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")
#         continue
#
# # DataFrame ìƒì„± ë° ì—‘ì…€ ì €ì¥
# df = pd.DataFrame(rows)
# df.to_excel("lklab_item_codes_vertical_grouped.xlsx", index=False)
#
# print("âœ… ê·¸ë£¹í™”ëœ ì„¸ë¡œ ì €ì¥ ì™„ë£Œ ë° ì—‘ì…€ ì €ì¥ë¨.")
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ğŸ‘‰ ì—‘ì…€ì—ì„œ ìƒí’ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
df_input = pd.read_excel("lklab_total_product_code.xlsx")  # íŒŒì¼ëª…ë§Œ ë°”ê¾¸ì„¸ìš”
g_no_list = df_input.iloc[:, 0].dropna().astype(int).tolist()

# ğŸ‘‰ ì„¸ì…˜ + ì¬ì‹œë„ ì„¤ì •
session = requests.Session()
retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
session.mount("https://", HTTPAdapter(max_retries=retries))

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/115.0.0.0 Safari/537.36"
}

base_iframe_url = "https://www.lklab.com/product/product_info_order_job.asp?g_no="
rows = []
cnt = 0
for g_no in g_no_list:
    cnt += 1
    iframe_url = f"{base_iframe_url}{g_no}"
    print(f"[INFO] {cnt}ë²ˆì§¸ ìƒí’ˆ {g_no} ì²˜ë¦¬ ì¤‘...")

    try:
        response = session.get(iframe_url, headers=headers, timeout=30)
        if response.status_code != 200:
            print(f"  âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
            continue

        soup = BeautifulSoup(response.text, "html.parser")
        item_codes = [td.get_text(strip=True) for td in soup.find_all("td", class_="pr22")]

        if not item_codes:
            print("  âš ï¸ í’ˆëª©ì½”ë“œ ì—†ìŒ")

        # g_noëŠ” ì²« í–‰ì—ë§Œ
        for idx, item_code in enumerate(item_codes):
            rows.append({
                "g_no": g_no if idx == 0 else "",
                "item_code": item_code
            })

        # time.sleep(random.uniform(1.5, 3.0))  # ëœë¤ ì§€ì—°

    except Exception as e:
        print(f"  âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")
        continue

# ê²°ê³¼ ì €ì¥
df = pd.DataFrame(rows)
df.to_excel("lklab_product_option.xlsx", index=False)
print("âœ… ì„¸ë¡œí˜• ì—‘ì…€ ì €ì¥ ì™„ë£Œ.")
